import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import os
import sys
import copy

# ×”×•×¡×¤×ª ×”×ª×™×§×™×™×” ×”×¨××©×™×ª ×œ-Path ×›×“×™ ×©× ×•×›×œ ×œ×™×™×‘× ××•×“×œ×™×
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.nes2net import Nes2Net

# --- ×”×’×“×¨×•×ª ---
DATA_ROOT = "../data"
PROTOCOLS_DIR = os.path.join(DATA_ROOT, "protocols")
FEATS_WAVLM = os.path.join(DATA_ROOT, "feats_wavlm")
FEATS_WHISPER = os.path.join(DATA_ROOT, "feats_whisper")
RESULTS_DIR = "../results"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ×¤×¨××˜×¨×™× ×œ××™××•×Ÿ
BATCH_SIZE = 16 # ×× ×™×© ×œ×š GPU ×—×–×§, ××¤×©×¨ ×œ×”×’×“×™×œ ×œ-32
EPOCHS = 20     # ××¡×¤×™×§ ×œ-POC
LR = 0.0001     # ×§×¦×‘ ×œ××™×“×”

# --- 1. Dataset Class ×—×›× ---
class FeatureDataset(Dataset):
    def __init__(self, mode, split='train'):
        """
        mode: 'wavlm', 'whisper', 'fusion'
        split: 'train' or 'test'
        """
        self.mode = mode
        self.split = split
        
        # ×˜×¢×™× ×ª ×”×¤×¨×•×˜×•×§×•×œ (×¨×©×™××ª ×”×§×‘×¦×™× ×•×”×ª×•×•×™×•×ª)
        protocol_file = os.path.join(PROTOCOLS_DIR, f"{split}_protocol.txt")
        self.file_list = []
        self.labels = []
        
        with open(protocol_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                fname = parts[0]
                label_str = parts[1] # 'bonafide' or 'spoof'
                
                self.file_list.append(fname)
                # ×”××¨×” ×œ××¡×¤×¨×™×: bonafide (×××™×ª×™) = 1, spoof (××–×•×™×£) = 0
                self.labels.append(1 if label_str == 'bonafide' else 0)

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        fname = self.file_list[idx]
        label = self.labels[idx]
        
        # × ×ª×™×‘×™× ×œ×§×‘×¦×™ ×”×¤×™×¦'×¨×™×
        # (×× ×—× ×• ×× ×™×—×™× ×©×”×”×¨×—×‘×” ×”×™× .pt ×›×™ ×—×™×œ×¦× ×• ××•×ª× ×§×•×“×)
        wavlm_path = os.path.join(FEATS_WAVLM, fname + ".pt")
        whisper_path = os.path.join(FEATS_WHISPER, fname + ".pt")
        
        # ×˜×¢×™× ×” ×œ×¤×™ ×”××•×“ (Mode)
        try:
            if self.mode == 'wavlm':
                feat = torch.load(wavlm_path) # [1, Time, 768]
                
            elif self.mode == 'whisper':
                feat = torch.load(whisper_path) # [1, Time, 768]
                
            elif self.mode == 'fusion':
                feat_w = torch.load(wavlm_path)     # WavLM
                feat_s = torch.load(whisper_path)   # Whisper
                
                # --- ×¡× ×›×¨×•×Ÿ (Alignment) ---
                # Whisper ×•-WavLM ×‘××•×¨×›×™× ×©×•× ×™×. × ×¡× ×›×¨×Ÿ ×œ×¤×™ WavLM.
                target_len = feat_w.shape[1]
                
                # ××ª×™×—×ª Whisper
                feat_s = feat_s.transpose(1, 2) # [1, 768, Time]
                feat_s = torch.nn.functional.interpolate(feat_s, size=target_len, mode='linear')
                feat_s = feat_s.transpose(1, 2) # [1, Time, 768]
                
                # ×©×¨×©×•×¨ (Concatenation)
                feat = torch.cat((feat_w, feat_s), dim=2) # [1, Time, 1536]
                
        except FileNotFoundError as e:
            # ×‘××§×¨×” ×©×§×•×‘×¥ ×—×¡×¨ (×œ× ×××•×¨ ×œ×§×¨×•×ª ×× ×—×™×œ×¦×ª ×”×›×œ)
            print(f"Error loading {fname}: {e}")
            return torch.zeros(768, 400), label

        # ×¢×™×‘×•×“ ×¡×•×¤×™ ×œ-Nes2Net
        # Nes2Net ×¨×•×¦×”: [Channels, Time] ×•×œ×œ× ××™××“ ×”-Batch ×”×¨××©×•×Ÿ ×©×œ ×”-Loader
        feat = feat.squeeze(0).transpose(0, 1) # [Channels, Time]
        
        # ×—×™×ª×•×š ××• ×¨×™×¤×•×“ ×œ××•×¨×š ×§×‘×•×¢ (×›×“×™ ×©× ×•×›×œ ×œ×¢×©×•×ª Batch)
        max_len = 400
        if feat.shape[1] > max_len:
            feat = feat[:, :max_len]
        else:
            padding = max_len - feat.shape[1]
            feat = torch.nn.functional.pad(feat, (0, padding))
            
        return feat, label

# --- 2. ×¤×•× ×§×¦×™×•×ª ××™××•×Ÿ ×•×‘×“×™×§×” ---
def train_one_epoch(model, loader, optimizer, criterion):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for feats, labels in loader:
        feats, labels = feats.to(DEVICE), labels.to(DEVICE)
        
        optimizer.zero_grad()
        outputs = model(feats) # Nes2Net output
        
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
    return total_loss / len(loader), 100 * correct / total

def evaluate(model, loader, criterion):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for feats, labels in loader:
            feats, labels = feats.to(DEVICE), labels.to(DEVICE)
            outputs = model(feats)
            loss = criterion(outputs, labels)
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
    return total_loss / len(loader), 100 * correct / total

# --- 3. ×”×× ×•×¢ ×”×¨××©×™ ×©××¨×™×¥ ××ª ×”× ×™×¡×•×™×™× ---
def run_experiment(mode_name):
    print(f"\n{'='*40}")
    print(f"ğŸš€ ××ª×—×™×œ × ×™×¡×•×™: {mode_name.upper()}")
    print(f"{'='*40}")
    
    # ×”×’×“×¨×ª ×’×•×“×œ ×”×§×œ×˜
    input_dim = 1536 if mode_name == 'fusion' else 768
    
    # ××ª×—×•×œ ×”××•×“×œ (Nes2Net ×”× ×§×™)
    model = Nes2Net(input_channels=input_dim).to(DEVICE)
    
    # ××ª×—×•×œ DataLoaders
    train_ds = FeatureDataset(mode=mode_name, split='train')
    test_ds = FeatureDataset(mode=mode_name, split='test')
    
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    best_acc = 0.0
    
    for epoch in range(EPOCHS):
        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)
        test_loss, test_acc = evaluate(model, test_loader, criterion)
        
        print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%")
        
        # ×©××™×¨×ª ×”××•×“×œ ×”×›×™ ×˜×•×‘
        if test_acc > best_acc:
            best_acc = test_acc
            # ×©××™×¨×ª ×”××©×§×•×œ×•×ª
            os.makedirs(RESULTS_DIR, exist_ok=True)
            torch.save(model.state_dict(), f"{RESULTS_DIR}/best_model_{mode_name}.pth")
            
    print(f"ğŸ ×¡×™×›×•× × ×™×¡×•×™ {mode_name}: Best Test Accuracy = {best_acc:.2f}%")
    return best_acc

# --- 4. ×”×¨×¦×” ×¨××©×™×ª ---
if __name__ == "__main__":
    if not os.path.exists(FEATS_WAVLM):
        print("âŒ ×©×’×™××”: ×œ× × ××¦××• ×¤×™×¦'×¨×™× ××—×•×œ×¦×™×. ×× × ×”×¨×™×¦×™ ×§×•×“× ××ª extract_features.py")
        exit()

    results = {}
    
    # × ×™×¡×•×™ 1: WavLM ×‘×œ×‘×“ (Baseline)
    results['WavLM'] = run_experiment('wavlm')
    
    # × ×™×¡×•×™ 2: Whisper ×‘×œ×‘×“ (Semantics)
    results['Whisper'] = run_experiment('whisper')
    
    # × ×™×¡×•×™ 3: Fusion (×”××•×“×œ ×©×œ×›×)
    results['Fusion'] = run_experiment('fusion')
    
    # ×”×“×¤×¡×ª ×˜×‘×œ×ª ×¡×™×›×•×
    print("\n\nğŸ“Š --- ×˜×‘×œ×ª ×ª×•×¦××•×ª ×¡×•×¤×™×ª --- ğŸ“Š")
    print(f"{'Model':<15} | {'Accuracy':<10}")
    print("-" * 30)
    for name, acc in results.items():
        print(f"{name:<15} | {acc:.2f}%")
    
    print("-" * 30)
    if results['Fusion'] > results['WavLM']:
        print("âœ… ×”×¦×œ×—×”! ××•×“×œ ×”-Fusion ×”×©×™×’ ×ª×•×¦××” ×˜×•×‘×” ×™×•×ª×¨ ××”×‘×¡×™×¡.")
    else:
        print("âš ï¸ ×©×™× ×œ×‘: ×”-Fusion ×œ× ×©×™×¤×¨ ××ª ×”×ª×•×¦××”. × ×“×¨×© ×›×•×•× ×•×Ÿ × ×•×¡×£.")