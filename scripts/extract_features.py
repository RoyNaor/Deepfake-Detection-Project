import torch
import torchaudio
from transformers import WavLMModel, WhisperModel
import os
from tqdm import tqdm

# --- ×”×’×“×¨×•×ª × ×ª×™×‘×™× ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜ ×”×¨××©×™×ª
RAW_AUDIO_DIR = os.path.join(BASE_DIR, "data", "raw_audio")
FEATS_WAVLM_DIR = os.path.join(BASE_DIR, "data", "feats_wavlm")
FEATS_WHISPER_DIR = os.path.join(BASE_DIR, "data", "feats_whisper")

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def extract_for_folder(model_wavlm, model_whisper, subfolder):
    """
    ×¤×•× ×§×¦×™×” ×©××§×‘×œ×ª ×©× ×©×œ ×ª×ª-×ª×™×§×™×™×” (train ××• test) ×•××—×œ×¦×ª ××ª ×›×œ ×”×§×‘×¦×™× ×©×‘×ª×•×›×”
    """
    input_dir = os.path.join(RAW_AUDIO_DIR, subfolder)
    
    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×™×¢×“ ×ª×•×××•×ª
    out_wavlm = os.path.join(FEATS_WAVLM_DIR, subfolder)
    out_whisper = os.path.join(FEATS_WHISPER_DIR, subfolder)
    
    os.makedirs(out_wavlm, exist_ok=True)
    os.makedirs(out_whisper, exist_ok=True)
    
    # ×¨×©×™××ª ×›×œ ×§×‘×¦×™ ×”××•×“×™×•
    files = [f for f in os.listdir(input_dir) if f.endswith('.flac')]
    
    print(f"\nğŸ“‚ ××¢×‘×“ ××ª ×ª×™×§×™×™×ª: {subfolder} ({len(files)} ×§×‘×¦×™×)...")
    
    for fname in tqdm(files):
        file_path = os.path.join(input_dir, fname)
        save_name = fname.replace('.flac', '.pt')
        
        # ×‘×“×™×§×” ×× ×›×‘×¨ ×¢×©×™× ×• ××ª ×”×§×•×‘×¥ ×”×–×” (×›×“×™ ×œ×—×¡×•×š ×–××Ÿ ×× ×¢×•×¦×¨×™× ×‘×××¦×¢)
        if os.path.exists(os.path.join(out_wavlm, save_name)) and \
           os.path.exists(os.path.join(out_whisper, save_name)):
            continue

        try:
            # 1. ×˜×¢×™× ×ª ××•×“×™×•
            waveform, sr = torchaudio.load(file_path)
            
            # Resampling ×—×•×‘×” ×œ-16kHz (×©× ×™ ×”××•×“×œ×™× ×“×•×¨×©×™× ××ª ×–×”)
            if sr != 16000:
                waveform = torchaudio.functional.resample(waveform, sr, 16000)
            
            # ×”×•×¡×¤×ª ××™××“ Batch ×× ×—×¡×¨ (×¦×¨×™×š ×œ×”×™×•×ª [1, Time])
            if waveform.dim() == 1:
                waveform = waveform.unsqueeze(0)
            
            waveform = waveform.to(DEVICE)
            
            with torch.no_grad():
                # --- A. ×—×™×œ×•×¥ WavLM ---
                # WavLM ××¦×¤×” ×œ-Raw Audio
                wavlm_out = model_wavlm(waveform).last_hidden_state # [1, Time, 768]
                torch.save(wavlm_out.cpu(), os.path.join(out_wavlm, save_name))
                
                # --- B. ×—×™×œ×•×¥ Whisper ---
                # Whisper ××¦×¤×” ×’× ×œ-Raw Audio (×‘×©×™××•×© ×‘-Feature Extractor ×”×¤× ×™××™ ×©×œ×•)
                # × ×©×ª××© ×™×©×™×¨×•×ª ×‘-Encoder
                whisper_out = model_whisper.encoder(waveform).last_hidden_state # [1, Time, 768]
                torch.save(whisper_out.cpu(), os.path.join(out_whisper, save_name))
                
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×§×•×‘×¥ {fname}: {e}")

def main():
    print(f"ğŸš€ ××ª×—×™×œ ×—×™×œ×•×¥ ×××¤×™×™× ×™× ×¢×œ {DEVICE}")
    
    # 1. ×˜×¢×™× ×ª ×”××•×“×œ×™× ×”×›×‘×“×™× ×œ×–×™×›×¨×•×Ÿ (×¤×¢× ××—×ª ×‘×œ×‘×“)
    print("Loading WavLM...")
    wavlm = WavLMModel.from_pretrained("microsoft/wavlm-base-plus").to(DEVICE)
    wavlm.eval() # ××¦×‘ ×§×¨×™××” ×‘×œ×‘×“
    
    print("Loading Whisper...")
    whisper = WhisperModel.from_pretrained("openai/whisper-small").to(DEVICE)
    whisper.eval()
    
    # 2. ×”×¨×¦×” ×¢×œ ×ª×™×§×™×™×ª ×”××™××•×Ÿ
    if os.path.exists(os.path.join(RAW_AUDIO_DIR, "train")):
        extract_for_folder(wavlm, whisper, "train")
    else:
        print("âš ï¸ ×œ× ××¦××ª×™ ×ª×™×§×™×™×ª train! ×”×× ×”×¨×¦×ª ××ª organize_data.py?")

    # 3. ×”×¨×¦×” ×¢×œ ×ª×™×§×™×™×ª ×”×˜×¡×˜
    if os.path.exists(os.path.join(RAW_AUDIO_DIR, "test")):
        extract_for_folder(wavlm, whisper, "test")
        
    print("\nâœ…âœ…âœ… ×¡×™×™×× ×•! ×›×œ ×”×××¤×™×™× ×™× ×—×•×œ×¦×• ×•××•×›× ×™× ×œ××™××•×Ÿ.")

if __name__ == "__main__":
    main()